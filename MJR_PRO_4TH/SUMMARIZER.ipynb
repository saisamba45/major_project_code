{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T6FXNGynLI8?si=eTODx4Vs5Rl-vxre'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videourl = \"https://youtu.be/T6FXNGynLI8?si=eTODx4Vs5Rl-vxre\"\n",
    "\n",
    "# Extract video ID from the URL\n",
    "video_id = videourl.split(\"/\")[-1]\n",
    "\n",
    "video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/T6FXNGynLI8?si=eTODx4Vs5Rl-vxre\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x26907e91110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo \n",
    "\n",
    "video = YouTubeVideo(video_id)\n",
    "\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pytube import YouTube\n",
    "\n",
    "def transcribe(url):\n",
    "    wspr = whisper.load_model('base')\n",
    "    ytrl = YouTube(url)\n",
    "    streams = ytrl.streams.filter(only_audio = True)\n",
    "    stream = streams.first()\n",
    "    stream.download(filename = 'audio1.mp4')\n",
    "    transcript = wspr.transcribe('audio1.mp4')\n",
    "    transcript = transcript['text']\n",
    "    return transcript\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transcript available...so creating one..\n",
      "please wait for few minutes..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#transcripts = YouTubeTranscriptApi.get_transcript(video_id)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtranscripts\u001b[49m:\n\u001b[0;32m      5\u001b[0m         total_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transcripts' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo transcript available...so creating one..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease wait for few minutes..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m total_content \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideourl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(total_content)\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      8\u001b[0m stream \u001b[38;5;241m=\u001b[39m streams\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m      9\u001b[0m stream\u001b[38;5;241m.\u001b[39mdownload(filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio1.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m transcript \u001b[38;5;241m=\u001b[39m \u001b[43mwspr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maudio1.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m transcript \u001b[38;5;241m=\u001b[39m transcript[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transcript\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:279\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\transcribe.py:195\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    192\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    194\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m--> 195\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    199\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    201\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[1;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[0;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[1;34m(self, tokens, audio_features)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[1;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 211\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:136\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    131\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     kv_cache: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    135\u001b[0m ):\n\u001b[1;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m    138\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:84\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kv_cache:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x \u001b[38;5;28;01mif\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[1;32m---> 84\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# for cross-attention, calculate keys and values once and reuse in subsequent calls.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1566\u001b[0m     ):\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kavya Katta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:37\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transcripts = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    total_content = \"\"\n",
    "\n",
    "    for i in transcripts:\n",
    "        total_content += \" \" + i['text']\n",
    "\n",
    "    print(total_content)\n",
    "except:\n",
    "    print(\"No transcript available...so creating one..\")\n",
    "    print('please wait for few minutes..')\n",
    "    total_content = transcribe(videourl)\n",
    "    print(total_content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The detected language is: ur\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        return language\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting language: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "#text_to_detect = \"यह तोह बोहोत ही आसान है \"\n",
    "\n",
    "detected_language = detect_language(total_content)\n",
    "\n",
    "if detected_language:\n",
    "    print(f\"The detected language is: {detected_language}\")\n",
    "else:\n",
    "    print(\"Language detection failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered\n",
      "My Sati Etober today I am very happy to welcome you as Akfilo Etober. It's been a long time since I've been there and there's a country number. There is a chance that we can make SMPEC more effective. If I am in Bish, I refuse to talk to you about some Bishas. These Bishes are those who are connected to the mass believers. The strength of the country's government is half of their strength. The Abhiyan made everyone give their contribution. The children gave it an emotional poral. The Sally British raised it. The war made it a mation in India's corner. We will not stop until this becomes the identity of thinking India, so every one of you should have a thinking animal in the priority. Another thing is that due to the success of digital payments UPI, India is currently at 46th place in the digital payments of the world. You should encourage the people of the country to make digital payments, teach them how to make digital payments in an easy way from your teacher, and one thing is that there are so many products that are made locally at the local level in our country. The scale of Satnia artisans is huge, but you can help to make Barat's locality global by working on your work and I will do one more thing. I am the signad of our madti ki jes prodik I have a sweat of some men of my country some artisan we will buy that thing let's go I enjoyed talking to all of you please subscribe my echla and you will get my own sikhs for it. Bell Akin will surely press you all to believe the whole network to me\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "if detected_language != 'en':\n",
    "    print('entered')\n",
    "    translator = Translator()\n",
    "    out = translator.translate(total_content,dest='en')\n",
    "    total_content = out.text\n",
    "\n",
    "print(total_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_content.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    'facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained(\n",
    "    'facebook/bart-large-cnn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summeries = []\n",
    "\n",
    "def summarize(text, maxSummarylength=500):\n",
    "    # Encode the text and summarize\n",
    "    inputs = tokenizer.encode(\"summarize: \" +\n",
    "                              text,\n",
    "                              return_tensors=\"pt\",\n",
    "                              max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=maxSummarylength/3*2,\n",
    "                                 min_length=int(maxSummarylength/5),\n",
    "                                 length_penalty=10.0,\n",
    "                                 num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_pieces(text,\n",
    "                           max_tokens=900,\n",
    "                           overlapPercent=10):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Calculate the overlap in tokens\n",
    "    overlap_tokens = int(max_tokens * overlapPercent / 100)\n",
    "\n",
    "    # Split the tokens into chunks of size\n",
    "    # max_tokens with overlap\n",
    "    pieces = [tokens[i:i + max_tokens]\n",
    "              for i in range(0, len(tokens),\n",
    "                             max_tokens - overlap_tokens)]\n",
    "\n",
    "    print('pieces======>>>>>>>>>>>',pieces)\n",
    "\n",
    "    # Convert the token pieces back into text\n",
    "    text_pieces = [tokenizer.decode(\n",
    "        tokenizer.convert_tokens_to_ids(piece),\n",
    "        skip_special_tokens=True) for piece in pieces]\n",
    "\n",
    "    return text_pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recursive_summarize(text, max_length=150, recursionLevel=0):\n",
    "    recursionLevel=recursionLevel+1\n",
    "    print(\"######### Recursion level: \",\n",
    "          recursionLevel,\"\\n\\n######### \")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    expectedCountOfChunks = len(tokens)/max_length\n",
    "    max_length=int(len(tokens)/expectedCountOfChunks)+2\n",
    "   \n",
    "    print(max_length)\n",
    "    # Break the text into pieces of max_length\n",
    "    pieces = split_text_into_pieces(text, max_tokens=max_length)\n",
    "\n",
    "    print(\"Number of pieces: \", len(pieces))\n",
    "    # Summarize each piece\n",
    "    summaries=[]\n",
    "    k=0\n",
    "    for k in range(0, len(pieces)):\n",
    "        piece=pieces[k]\n",
    "        #print(\"****************************************************\")\n",
    "        #print(\"Piece:\",(k+1),\" out of \", len(pieces), \"pieces\")\n",
    "        #print(piece, \"\\n\")\n",
    "        summary =summarize(piece, maxSummarylength=max_length)\n",
    "        #print(\"SUMNMARY: \", summary)\n",
    "        summaries.append(summary)\n",
    "        #print(\"****************************************************\")\n",
    "\n",
    "    concatenated_summary = ' '.join(summaries)\n",
    "    all_summeries.append(concatenated_summary)\n",
    "    print('concat_summary',concatenated_summary)\n",
    "\n",
    "    tokens = tokenizer.tokenize(concatenated_summary)\n",
    "    print('length==',len(tokens))\n",
    "    if len(tokens) > max_length:\n",
    "        # If the concatenated_summary is too long, repeat the process\n",
    "        print(\"############# GOING RECURSIVE ##############\")\n",
    "        return recursive_summarize(concatenated_summary,\n",
    "                                   max_length=max_length,\n",
    "                                   recursionLevel=recursionLevel)\n",
    "    else:\n",
    "      # Concatenate the summaries and summarize again\n",
    "        final_summary=concatenated_summary\n",
    "        '''if len(pieces)>1:\n",
    "            final_summary = summarize(concatenated_summary,\n",
    "                                  maxSummarylength=max_length)'''\n",
    "        return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Recursion level:  1 \n",
      "\n",
      "######### \n",
      "152\n",
      "pieces======>>>>>>>>>>> [['Ġ50', '%', 'Ġof', 'ĠIndia', 'Ġis', 'Ġless', 'Ġthan', 'Ġthe', 'Ġage', 'Ġof', 'Ġ27', '.', 'ĠNow', 'Ġthis', 'Ġis', 'Ġa', 'Ġterrific', 'Ġdemographic', 'Ġdividend', 'Ġthat', 'Ġno', 'Ġgovernment', 'Ġin', 'Ġits', 'Ġright', 'Ġmind', 'Ġcan', 'Ġafford', 'Ġto', 'Ġignore', '.', 'ĠOur', 'Ġyoungsters', 'Ġtoday', 'Ġhave', 'Ġbeen', 'Ġexposed', 'Ġto', 'Ġthe', 'Ġworld', '.', 'ĠThey', 'Ġknow', 'Ġwhat', 'Ġis', 'Ġhappening', 'Ġin', 'Ġwash', 'Ġin', 'Ġsay', 'Ġwater', ',', 'Ġhygiene', 'Ġand', 'Ġsanitation', 'Ġin', 'ĠBrazil', 'Ġbecause', 'Ġyou', 'Ġtoo', 'Ġwhen', 'ĠGoogle', 'Ġall', 'Ġof', 'Ġthese', 'Ġsolutions', 'Ġconnect', 'Ġus', 'Ġlike', 'Ġnever', 'Ġbefore', 'Ġever', 'Ġin', 'Ġhistory', '.', 'ĠSo', 'Ġtherefore', 'Ġour', 'Ġyoungsters', 'Ġtoday', 'Ġhave', 'Ġthe', 'Ġability', ',', 'Ġhave', 'Ġthe', 'Ġimagination', ',', 'Ġhave', 'Ġthe', 'Ġvision', 'Ġand', 'Ġhave', 'Ġthe', 'Ġaud', 'acity', 'Ġto', 'Ġcompete', 'Ġwith', 'Ġthe', 'Ġworld', '.', 'ĠAnd', 'Ġtherefore', 'Ġgovernments', 'Ġin', 'ĠIndia', 'Ġbe', 'Ġit', 'Ġa', 'Ġstate', 'Ġgovernment', ',', 'Ġbe', 'Ġit', 'Ġa', 'Ġmunicipal', 'Ġlocal', 'Ġadministration', 'Ġor', 'Ġbeat', 'Ġgovernment', 'Ġof', 'ĠIndia', 'Ġwe', 'Ġcannot', 'Ġafford', 'Ġto', 'Ġmiss', 'Ġout', 'Ġon', 'Ġthis', 'Ġdemographic', 'Ġdividend', '.', 'ĠThat', \"'s\", 'Ġwhy', 'ĠI', 'Ġsaid', 'Ġinnovation', ',', 'Ġfocus', 'Ġon', 'Ġinnovation', '.', 'ĠWhat', 'Ġdo', 'ĠI', 'Ġmean', 'Ġinnovation', '?'], ['Ġwhy', 'ĠI', 'Ġsaid', 'Ġinnovation', ',', 'Ġfocus', 'Ġon', 'Ġinnovation', '.', 'ĠWhat', 'Ġdo', 'ĠI', 'Ġmean', 'Ġinnovation', '?', 'ĠI', 'Ġjust', 'Ġdon', \"'t\", 'Ġmean', 'Ġtech', 'Ġinnovation', '.', 'ĠThere', 'Ġis', 'Ġsocial', 'Ġinnovation', ',', 'Ġthere', 'Ġis', 'Ġrural', 'Ġinnovation', ',', 'Ġof', 'Ġcourse', 'Ġthere', 'Ġis', 'Ġtech', 'Ġinnovation', '.', 'ĠIf', 'ĠIndia', 'Ġcan', 'Ġsolve', 'Ġits', 'Ġproblem', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġwater', ',', 'Ġsanitation', 'Ġand', 'Ġhygiene', ',', 'Ġyou', \"'re\", 'Ġsolving', 'Ġone', 'Ġfifth', 'Ġof', 'Ġthe', 'Ġworld', 'Ġproblem', 'Ġand', 'Ġobviously', 'Ġby', 'Ġscaling', 'Ġit', 'Ġup', 'Ġyou', 'Ġpossibly', 'Ġcan', 'Ġsolve', 'Ġthe', 'Ġproblems', 'Ġof', 'Ġthe', 'Ġremaining', 'Ġdeveloping', 'Ġnations', ',', 'Ġemerging', 'Ġnations', 'Ġas', 'Ġthey', 'Ġare', 'Ġcalled', '.', 'ĠThe', 'Ġfirst', 'Ġword', 'Ġdoesn', \"'t\", 'Ġneed', 'Ġthese', 'Ġsolutions', 'Ġmaybe', 'Ġbut', 'ĠI', 'Ġthink', 'Ġthe', 'Ġemerging', 'Ġcountries', 'Ġwhich', 'Ġare', 'Ġsimilar', 'Ġto', 'ĠIndia', ',', 'ĠI', 'Ġthink', 'Ġthey', 'Ġall', 'Ġneed', 'Ġour', 'Ġsolution', '.', 'ĠSo', 'Ġif', 'Ġyou', 'Ġhave', 'Ġa', 'Ġproof', 'Ġof', 'Ġconcept', 'Ġwhich', 'Ġworks', 'Ġin', 'ĠIndia', ',', 'Ġit', 'Ġwill', 'Ġwork', ',', 'Ġit', 'Ġwill', 'Ġwork', 'Ġeverywhere', 'Ġelse', 'Ġin', 'Ġthe', 'Ġworld', '.', 'ĠSo', 'Ġtherefore', 'Ġour', 'Ġyoung', 'Ġinnov', 'ators', 'Ġneed', 'Ġto'], ['Ġwork', 'Ġeverywhere', 'Ġelse', 'Ġin', 'Ġthe', 'Ġworld', '.', 'ĠSo', 'Ġtherefore', 'Ġour', 'Ġyoung', 'Ġinnov', 'ators', 'Ġneed', 'Ġto', 'Ġbe', 'Ġencouraged', ',', 'Ġthey', 'Ġneed', 'Ġto', 'Ġbe', 'Ġcherished', ',', 'Ġthey', 'Ġneed', 'Ġto', 'Ġbe', 'Ġgiven', 'Ġthe', 'Ġplatform', ',', 'Ġas', 'Ġyou', 'Ġknow', 'Ġred', 'Ġbull', 'Ġcard', ',', 'Ġif', 'Ġyou', 'Ġhave', 'Ġwings', 'Ġyou', 'Ġcan', 'Ġfly', 'Ġor', 'Ġsomething', 'Ġlike', 'Ġthat', '.', 'ĠSo', 'ĠI', 'Ġthink', 'Ġour', 'Ġyoungsters', 'Ġneed', 'Ġthose', 'Ġwings', ',', 'Ġyou', 'Ġneed', 'Ġto', 'Ġbe', 'Ġable', 'Ġto', 'Ġgive', 'Ġwings', 'Ġto', 'Ġtheir', 'Ġaspirations', 'Ġas', 'Ġlong', 'Ġas', 'Ġyou', 'Ġare', 'Ġable', 'Ġto', 'Ġgive', 'Ġit', 'Ġto', 'Ġthem', '.', 'ĠI', 'Ġthink', 'Ġthey', 'Ġall', 'Ġconquer', 'Ġthe', 'Ġworld', ',', 'Ġthat', \"'s\", 'Ġthe', 'Ġfirst', 'Ġthing', 'ĠI', 'Ġtold', 'Ġthem', '.', 'ĠThe', 'Ġthree', 'ĠI', \"'m\", 'Ġent', 'h', 'ron', 'ed', ',', 'Ġfirst', 'Ġis', 'Ġinnovation', ',', 'Ġsecond', 'Ġis', 'Ġinfrastructure', '.', 'ĠToday', 'Ġthe', 'Ġgovernment', 'Ġof', 'ĠTel', 'ang', 'ana', 'Ġis', 'Ġgoing', 'Ġout', 'Ġon', 'Ġa', 'Ġlimb', ',', 'Ġwe', \"'re\", 'Ġnot', 'Ġjust', 'Ġhappy', 'Ġbeing', 'Ġan', 'ĠO', 'DF', 'Ġor', 'ĠO', 'DF', '++', 'Ġstay', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġour', 'Ġtowns', 'Ġand', 'Ġsanitation'], ['Ġan', 'ĠO', 'DF', 'Ġor', 'ĠO', 'DF', '++', 'Ġstay', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġour', 'Ġtowns', 'Ġand', 'Ġsanitation', '.', 'ĠWe', 'Ġare', 'Ġin', 'Ġfact', 'Ġgoing', 'Ġto', 'Ġbe', 'Ġpossibly', 'Ġone', 'Ġof', 'Ġthe', 'Ġfirst', 'Ġstates', 'Ġin', 'Ġthe', 'Ġcountry', 'Ġwhich', 'Ġwill', 'Ġhave', 'Ġa', 'Ġfec', 'al', 'Ġsl', 'udge', 'Ġtreatment', 'Ġplant', 'Ġin', 'Ġeach', 'Ġof', 'Ġits', 'Ġtowns', ',', 'Ġit', 'Ġis', 'Ġambitious', ',', 'Ġit', 'Ġis', 'Ġaud', 'acious', 'Ġbut', 'ĠI', 'Ġthink', 'Ġwe', 'Ġare', 'Ġon', 'Ġthe', 'Ġright', 'Ġcourse', 'Ġalong', 'Ġwith', 'ĠAs', 'ki', 'Ġas', 'Ġour', 'Ġknowledge', 'Ġpartner', ',', 'Ġwe', 'Ġhave', 'Ġfloated', 'Ġa', 'Ġtender', ',', 'Ġwe', \"'ve\", 'Ġalready', 'Ġstarted', 'Ġworking', 'ĠI', 'Ġthink', 'Ġabout', 'Ġ26', 'Ġtowns', ',', 'Ġthe', 'Ġwork', 'Ġis', 'Ġongoing', 'Ġand', 'ĠI', 'Ġdon', \"'t\", 'Ġbelieve', 'Ġthat', 'Ġwe', 'Ġwill', 'Ġalso', 'Ġcomplete', 'Ġthe', 'Ġremaining', 'Ġ125', 'Ġother', 'Ġtowns', 'Ġand', 'Ġwill', 'Ġpossibly', 'Ġbe', 'Ġthe', 'Ġfirst', 'Ġstate', 'Ġin', 'Ġthe', 'Ġcountry', 'Ġto', 'Ġhave', 'Ġaccomplished', 'Ġthis', 'Ġrare', 'Ġfeat', 'Ġof', 'Ġbeing', 'ĠO', 'DF', '++', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġtowns', 'Ġand', 'Ġfre', 'q', 'Ġsl', 'udge', 'Ġtreatment', '.', 'ĠInfrastructure', ',', 'Ġwhat', 'Ġdo', 'ĠI', 'Ġmean', 'Ġwhen', 'ĠI', 'Ġsay', 'Ġinfrastructure'], ['q', 'Ġsl', 'udge', 'Ġtreatment', '.', 'ĠInfrastructure', ',', 'Ġwhat', 'Ġdo', 'ĠI', 'Ġmean', 'Ġwhen', 'ĠI', 'Ġsay', 'Ġinfrastructure', ',', 'Ġinfrastructure', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġwater', ',', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġhygiene', ',', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġeverything', ',', 'Ġwe', 'Ġcannot', 'Ġafford', 'Ġnot', 'Ġto', 'Ġhave', 'Ġinfrastructure', 'Ġas', 'Ġan', 'Ġemerging', 'Ġnation', 'Ġas', 'Ġa', 'Ġdeveloping', 'Ġcountry', 'Ġand', 'Ġthe', 'Ġlast', 'Ġthing', 'Ġon', 'Ġthree', 'ĠI', \"'m\", 'Ġent', 'h', 'ron', 'ed', 'Ġthat', 'ĠI', 'Ġmentioned', 'Ġto', 'ĠHonour', 'able', 'ĠPrime', 'ĠMinister', ',', 'Ġinnovation', ',', 'Ġinfrastructure', 'Ġand', 'Ġmost', 'Ġimportant', 'Ġis', 'Ġinclusive', 'Ġgrowth', '.', 'ĠWe', 'Ġcannot', 'Ġafford', 'Ġas', 'Ġa', 'Ġcountry', 'Ġto', 'Ġnot', 'Ġinclude', 'Ġour', 'Ġwomen', ',', 'Ġwe', 'Ġcannot', 'Ġafford', 'Ġas', 'Ġa', 'Ġcountry', 'Ġto', 'Ġlet', 'Ġthe', 'Ġrural', 'Ġgovernment', 'Ġdivide', 'Ġus', ',', 'Ġwe', 'Ġcannot', 'Ġafford', 'Ġin', 'Ġour', 'Ġcountry', 'Ġto', 'Ġlet', 'Ġour', 'Ġsocial', 'Ġclasses', 'Ġor', 'Ġour', 'Ġcaste', 'Ġsystem', 'Ġor', 'Ġour', 'Ġreligion', 'Ġdivide', 'Ġus', 'Ġwhen', 'Ġit', 'Ġcomes', 'Ġto', 'Ġthe', 'Ġgrowth', 'Ġin', 'Ġthis', 'Ġcountry', 'Ġor', 'Ġthe', 'Ġaspirations', 'Ġof', 'Ġthis', 'Ġnation', '.', 'ĠSo', 'Ġtherefore', 'Ġunless', 'Ġwe', 'Ġfocus', 'Ġon', 'Ġall', 'Ġthese', 'Ġthree', 'Ġand', 'Ġunless', 'Ġwe'], ['Ġthis', 'Ġnation', '.', 'ĠSo', 'Ġtherefore', 'Ġunless', 'Ġwe', 'Ġfocus', 'Ġon', 'Ġall', 'Ġthese', 'Ġthree', 'Ġand', 'Ġunless', 'Ġwe', 'Ġuse', 'Ġsome', 'Ġreally', 'Ġinnovative', 'Ġj', 'ugar', 'Ġmodel', 'Ġand', 'Ġwho', 'Ġknows', 'Ġj', 'ugar', 'Ġto', 'Ġbetter', 'Ġthan', 'ĠGujar', 'ati', \"'s\", 'Ġright', '.', 'ĠSo', 'Ġtherefore', 'Ġwith', 'Ġtwo', 'ĠGujar', 'ati', 'Ġleaders', 'Ġrunning', 'Ġour', 'Ġcountry', 'ĠI', 'Ġdo', 'Ġhope', 'Ġvery', 'Ġstrongly', ',', 'ĠAb', 'his', 'he', 'k', 'ĠI', 'Ġdo', 'Ġhope', 'Ġvery', 'Ġstrongly', '.', 'ĠYou', 'Ġare', 'Ġlaughing', 'Ġwhen', 'Ġyou', 'Ġare', 'Ġdoing', 'Ġhard', 'Ġso', 'Ġwith', 'Ġour', 'ĠPrime', 'ĠMinister', 'Ġhimself', 'Ġleading', 'Ġfrom', 'Ġthe', 'Ġfront', '.', 'ĠI', 'Ġdon', \"'t\", 'Ġbelieve', 'Ġthat', 'ĠIndia', 'Ġis', 'Ġactually', 'Ġheaded', 'Ġin', 'Ġthe', 'Ġright', 'Ġdirection', 'Ġand', 'ĠI', 'Ġdon', \"'t\", 'Ġfeel', 'Ġvery', 'Ġstrong', 'Ġhere', 'Ġand', 'ĠI', 'Ġfeel', 'Ġa', 'Ġgreat', 'Ġdeal', 'Ġof', 'Ġoptimism', '.', 'ĠOne', 'Ġof', 'Ġthe', 'Ġthings', 'Ġwe', 'Ġdid', 'Ġin', 'Ġterms', 'Ġof', 'Ġj', 'ugar', 'Ġwhen', 'Ġwe', 'Ġlaid', 'Ġthis', 'Ġ130', ',', '000', 'Ġkilometers', 'Ġof', 'Ġwater', 'Ġpipeline', ',', 'Ġthis', 'Ġpart', 'Ġof', 'Ġour', 'Ġdrinking', 'Ġwater', 'Ġproject', ',', 'Ġwe', 'Ġalso', 'Ġhave', 'Ġcombined', 'Ġin', 'Ġthe', 'Ġsame', 'Ġtrench', 'Ġfiber', 'Ġoptic', 'Ġcable'], ['Ġdrinking', 'Ġwater', 'Ġproject', ',', 'Ġwe', 'Ġalso', 'Ġhave', 'Ġcombined', 'Ġin', 'Ġthe', 'Ġsame', 'Ġtrench', 'Ġfiber', 'Ġoptic', 'Ġcable', '.', 'ĠSo', 'ĠN', 'alk', 'esh', 'ĠSar', 'ke', 'Ġsir', ',', 'Ġyou', 'Ġcan', 'Ġget', 'Ġa', 'Ġbroadband', 'Ġconnection', 'Ġwith', 'Ġthe', 'Ġfinal', 'Ġlake', 'Ġof', 'Ġfinishing', 'Ġthe', 'ĠD', '-', 'f', 'iber', 'Ġproject', 'Ġas', 'Ġwe', 'Ġcall', 'Ġit', 'Ġand', 'Ġonce', 'Ġthat', 'Ġis', 'Ġdone', 'Ġyou', 'Ġcan', 'Ġimagine', 'Ġthe', 'Ġpossibilities', 'Ġand', 'Ġwhat', 'Ġcan', 'Ġbe', 'Ġaccomplished', 'Ġwith', 'Ġgood', 'Ġhigh', 'Ġspeed', 'Ġbroadband', 'Ġeven', 'Ġwith', 'Ġthe', 'Ġlow', 'Ġstep', 'Ġof', 'Ġrural', 'Ġhousehold', ',', 'Ġe', '-', 'commerce', ',', 'Ġe', '-', 'health', ',', 'Ġeducation', 'Ġand', 'Ġaltitude', 'Ġof', 'Ġother', 'Ġthings', 'Ġthat', 'Ġcan', 'Ġhappen', 'Ġby', 'Ġway', 'Ġof', 'Ġthis', 'Ġconnection', 'Ġthat', 'Ġwe', 'Ġwill', 'Ġbe', 'Ġup', 'Ġand', 'Ġrunning', 'Ġin', 'Ġthe', 'Ġnext', 'Ġone', '.']]\n",
      "Number of pieces:  7\n",
      "concat_summary 50% of India is less than the age of 27. \"This is a terrific demographic dividend that no government in its right mind can afford to ignore,\" he says. If India can solve its problem with respect to water, sanitation and hygiene, you're solving one fifth of the world problem. By scaling it up you possibly can solve the problems of the remaining developing nations, emerging nations as they are called. Telangana is going out on a limb, we're not just happy being an ODF or ODF++ stay with respect to our towns and sanitation. I think our youngsters need those wings, you need to be able to give wings to their aspirations as long as you are able to. \"We are in fact going to be possibly one of the first states in the country which will have a fecal sludge treatment plant in each of its towns,\" he said. \"It is ambitious, it is audacious but I think we are on the right course,\" he added. \"Innovation, infrastructure and most important is inclusive growth. We cannot afford as a country to not include our women,\" he says. \"We cannot afford in our country to let our social classes or our caste system or our religion divide us\" I don't believe that India is actually headed in the right direction and I don't feel very strong here and I feel a great deal of optimism. So therefore with two Gujarati leaders running our country I do hope very strongly. You are laughing when you are doing hard. Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable. So you can get a broadband connection with the final lake of finishing the D-fiber project as we call it\"\n",
      "length== 347\n",
      "############# GOING RECURSIVE ##############\n",
      "######### Recursion level:  2 \n",
      "\n",
      "######### \n",
      "154\n",
      "pieces======>>>>>>>>>>> [['50', '%', 'Ġof', 'ĠIndia', 'Ġis', 'Ġless', 'Ġthan', 'Ġthe', 'Ġage', 'Ġof', 'Ġ27', '.', 'Ġ\"', 'This', 'Ġis', 'Ġa', 'Ġterrific', 'Ġdemographic', 'Ġdividend', 'Ġthat', 'Ġno', 'Ġgovernment', 'Ġin', 'Ġits', 'Ġright', 'Ġmind', 'Ġcan', 'Ġafford', 'Ġto', 'Ġignore', ',\"', 'Ġhe', 'Ġsays', '.', 'ĠIf', 'ĠIndia', 'Ġcan', 'Ġsolve', 'Ġits', 'Ġproblem', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġwater', ',', 'Ġsanitation', 'Ġand', 'Ġhygiene', ',', 'Ġyou', \"'re\", 'Ġsolving', 'Ġone', 'Ġfifth', 'Ġof', 'Ġthe', 'Ġworld', 'Ġproblem', '.', 'ĠBy', 'Ġscaling', 'Ġit', 'Ġup', 'Ġyou', 'Ġpossibly', 'Ġcan', 'Ġsolve', 'Ġthe', 'Ġproblems', 'Ġof', 'Ġthe', 'Ġremaining', 'Ġdeveloping', 'Ġnations', ',', 'Ġemerging', 'Ġnations', 'Ġas', 'Ġthey', 'Ġare', 'Ġcalled', '.', 'ĠTel', 'ang', 'ana', 'Ġis', 'Ġgoing', 'Ġout', 'Ġon', 'Ġa', 'Ġlimb', ',', 'Ġwe', \"'re\", 'Ġnot', 'Ġjust', 'Ġhappy', 'Ġbeing', 'Ġan', 'ĠO', 'DF', 'Ġor', 'ĠO', 'DF', '++', 'Ġstay', 'Ġwith', 'Ġrespect', 'Ġto', 'Ġour', 'Ġtowns', 'Ġand', 'Ġsanitation', '.', 'ĠI', 'Ġthink', 'Ġour', 'Ġyoungsters', 'Ġneed', 'Ġthose', 'Ġwings', ',', 'Ġyou', 'Ġneed', 'Ġto', 'Ġbe', 'Ġable', 'Ġto', 'Ġgive', 'Ġwings', 'Ġto', 'Ġtheir', 'Ġaspirations', 'Ġas', 'Ġlong', 'Ġas', 'Ġyou', 'Ġare', 'Ġable', 'Ġto', '.', 'Ġ\"', 'We', 'Ġare', 'Ġin', 'Ġfact', 'Ġgoing', 'Ġto', 'Ġbe', 'Ġpossibly', 'Ġone', 'Ġof', 'Ġthe', 'Ġfirst'], ['Ġto', '.', 'Ġ\"', 'We', 'Ġare', 'Ġin', 'Ġfact', 'Ġgoing', 'Ġto', 'Ġbe', 'Ġpossibly', 'Ġone', 'Ġof', 'Ġthe', 'Ġfirst', 'Ġstates', 'Ġin', 'Ġthe', 'Ġcountry', 'Ġwhich', 'Ġwill', 'Ġhave', 'Ġa', 'Ġfec', 'al', 'Ġsl', 'udge', 'Ġtreatment', 'Ġplant', 'Ġin', 'Ġeach', 'Ġof', 'Ġits', 'Ġtowns', ',\"', 'Ġhe', 'Ġsaid', '.', 'Ġ\"', 'It', 'Ġis', 'Ġambitious', ',', 'Ġit', 'Ġis', 'Ġaud', 'acious', 'Ġbut', 'ĠI', 'Ġthink', 'Ġwe', 'Ġare', 'Ġon', 'Ġthe', 'Ġright', 'Ġcourse', ',\"', 'Ġhe', 'Ġadded', '.', 'Ġ\"', 'In', 'n', 'ovation', ',', 'Ġinfrastructure', 'Ġand', 'Ġmost', 'Ġimportant', 'Ġis', 'Ġinclusive', 'Ġgrowth', '.', 'ĠWe', 'Ġcannot', 'Ġafford', 'Ġas', 'Ġa', 'Ġcountry', 'Ġto', 'Ġnot', 'Ġinclude', 'Ġour', 'Ġwomen', ',\"', 'Ġhe', 'Ġsays', '.', 'Ġ\"', 'We', 'Ġcannot', 'Ġafford', 'Ġin', 'Ġour', 'Ġcountry', 'Ġto', 'Ġlet', 'Ġour', 'Ġsocial', 'Ġclasses', 'Ġor', 'Ġour', 'Ġcaste', 'Ġsystem', 'Ġor', 'Ġour', 'Ġreligion', 'Ġdivide', 'Ġus', '\"', 'ĠI', 'Ġdon', \"'t\", 'Ġbelieve', 'Ġthat', 'ĠIndia', 'Ġis', 'Ġactually', 'Ġheaded', 'Ġin', 'Ġthe', 'Ġright', 'Ġdirection', 'Ġand', 'ĠI', 'Ġdon', \"'t\", 'Ġfeel', 'Ġvery', 'Ġstrong', 'Ġhere', 'Ġand', 'ĠI', 'Ġfeel', 'Ġa', 'Ġgreat', 'Ġdeal', 'Ġof', 'Ġoptimism', '.', 'ĠSo', 'Ġtherefore', 'Ġwith', 'Ġtwo', 'ĠGujar', 'ati', 'Ġleaders', 'Ġrunning', 'Ġour', 'Ġcountry', 'ĠI', 'Ġdo', 'Ġhope', 'Ġvery'], ['.', 'ĠSo', 'Ġtherefore', 'Ġwith', 'Ġtwo', 'ĠGujar', 'ati', 'Ġleaders', 'Ġrunning', 'Ġour', 'Ġcountry', 'ĠI', 'Ġdo', 'Ġhope', 'Ġvery', 'Ġstrongly', '.', 'ĠYou', 'Ġare', 'Ġlaughing', 'Ġwhen', 'Ġyou', 'Ġare', 'Ġdoing', 'Ġhard', '.', 'ĠN', 'alk', 'esh', 'ĠSar', 'ke', ':', 'Ġ\"', 'We', 'Ġalso', 'Ġhave', 'Ġcombined', 'Ġin', 'Ġthe', 'Ġsame', 'Ġtrench', 'Ġfiber', 'Ġoptic', 'Ġcable', '.', 'ĠSo', 'Ġyou', 'Ġcan', 'Ġget', 'Ġa', 'Ġbroadband', 'Ġconnection', 'Ġwith', 'Ġthe', 'Ġfinal', 'Ġlake', 'Ġof', 'Ġfinishing', 'Ġthe', 'ĠD', '-', 'f', 'iber', 'Ġproject', 'Ġas', 'Ġwe', 'Ġcall', 'Ġit', '\"']]\n",
      "Number of pieces:  3\n",
      "concat_summary 50% of India is less than the age of 27. If India can solve its problem with respect to water, sanitation and hygiene, you're solving one fifth of the world problem. Telangana is going out on a limb. \"I don't believe that India is actually headed in the right direction and I don't feel very strong here and I feel a great deal of optimism,\" he says. \"We cannot afford as a country to not include our women\" Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable. So you can get a broadband connection with the final lake of finishing\"\n",
      "length== 127\n",
      "['50% of India is less than the age of 27. \"This is a terrific demographic dividend that no government in its right mind can afford to ignore,\" he says. If India can solve its problem with respect to water, sanitation and hygiene, you\\'re solving one fifth of the world problem. By scaling it up you possibly can solve the problems of the remaining developing nations, emerging nations as they are called. Telangana is going out on a limb, we\\'re not just happy being an ODF or ODF++ stay with respect to our towns and sanitation. I think our youngsters need those wings, you need to be able to give wings to their aspirations as long as you are able to. \"We are in fact going to be possibly one of the first states in the country which will have a fecal sludge treatment plant in each of its towns,\" he said. \"It is ambitious, it is audacious but I think we are on the right course,\" he added. \"Innovation, infrastructure and most important is inclusive growth. We cannot afford as a country to not include our women,\" he says. \"We cannot afford in our country to let our social classes or our caste system or our religion divide us\" I don\\'t believe that India is actually headed in the right direction and I don\\'t feel very strong here and I feel a great deal of optimism. So therefore with two Gujarati leaders running our country I do hope very strongly. You are laughing when you are doing hard. Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable. So you can get a broadband connection with the final lake of finishing the D-fiber project as we call it\"', '50% of India is less than the age of 27. If India can solve its problem with respect to water, sanitation and hygiene, you\\'re solving one fifth of the world problem. Telangana is going out on a limb. \"I don\\'t believe that India is actually headed in the right direction and I don\\'t feel very strong here and I feel a great deal of optimism,\" he says. \"We cannot afford as a country to not include our women\" Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable. So you can get a broadband connection with the final lake of finishing\"']\n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%\n",
      "\n",
      "Final summary: 50% of India is less than the age of 27. If India can solve its problem with respect to water, sanitation and hygiene, you're solving one fifth of the world problem. Telangana is going out on a limb. \"I don't believe that India is actually headed in the right direction and I don't feel very strong here and I feel a great deal of optimism,\" he says. \"We cannot afford as a country to not include our women\" Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable. So you can get a broadband connection with the final lake of finishing\"\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "final_summary = recursive_summarize(total_content)\n",
    "\n",
    "print(all_summeries)\n",
    "print(\"\\n%%%%%%%%%%%%%%%%%%%%%\\n\")\n",
    "print(\"Final summary:\", final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 50% of India is less than the age of 27.\n",
      "2. If India can solve its problem with respect to water, sanitation and hygiene, you're solving one fifth of the world problem.\n",
      "3. \"I don't believe that India is actually headed in the right direction and I don't feel very strong here and I feel a great deal of optimism,\" he says.\n",
      "4. \"We cannot afford as a country to not include our women\" Nalkesh Sarke: \"We also have combined in the same trench fiber optic cable.\n",
      "5. So you can get a broadband connection with the final lake of finishing\"\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def sentence_importance(sentence):\n",
    "    return sum([word.vector_norm for word in sentence])\n",
    "\n",
    "def summarize_paragraph(paragraph, num_sentences=3):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the paragraph with spaCy\n",
    "    doc = nlp(paragraph)\n",
    "    \n",
    "    # Get sentences and their respective importance scores\n",
    "    sentences = [(sent, sentence_importance(sent)) for sent in doc.sents]\n",
    "    \n",
    "    # Sort sentences by importance score\n",
    "    sorted_sentences = sorted(sentences, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N sentences\n",
    "    top_sentences = sorted_sentences[:num_sentences]\n",
    "    \n",
    "    # Sort top sentences by their original order in the paragraph\n",
    "    top_sentences = sorted(top_sentences, key=lambda x: x[0].start)\n",
    "    \n",
    "    # Extract the text of the top sentences\n",
    "    summarized_text = [sent.text.strip() for sent, _ in top_sentences]\n",
    "    \n",
    "    return summarized_text\n",
    "\n",
    "# Example usage\n",
    "paragraph = \"\"\"\n",
    "The company's financial performance in the last quarter has been outstanding. \n",
    "Revenues exceeded expectations, showing a 15% growth compared to the previous year. \n",
    "The key drivers of this success were innovative product launches and effective cost management strategies.\n",
    "\"\"\"\n",
    "\n",
    "result = summarize_paragraph(all_summeries[-1], num_sentences=5)\n",
    "\n",
    "# Print the summarized text\n",
    "for i, sentence in enumerate(result, 1):\n",
    "    print(f\"{i}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Phrases (lengths 2, 3, and 4):\n",
      "['50%', 'the age', 'its problem', 'one fifth', 'the world problem', 'a limb', 'the right direction', 'a great deal', 'a country', 'our women', 'Nalkesh Sarke', 'a broadband connection', 'the final lake']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def identify_key_phrases(text, min_length=2, max_length=4):\n",
    "    try:\n",
    "        # Load the English NLP model from spaCy\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        # Process the input text\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Extract key phrases (noun chunks) of specific lengths from the processed document\n",
    "        key_phrases = [chunk.text for chunk in doc.noun_chunks if min_length <= len(chunk) <= max_length]\n",
    "        \n",
    "        return key_phrases\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "text = \"Natural Language Processing is a field of study that focuses on the interaction between computers and humans using natural language.\"\n",
    "key_phrases = identify_key_phrases(all_summeries[-1], min_length=2, max_length=4)\n",
    "\n",
    "if key_phrases is not None:\n",
    "    print(\"Key Phrases (lengths 2, 3, and 4):\")\n",
    "    print(key_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \u001b[1;31m50%\u001b[0m of India is less than \u001b[1;31mthe age\u001b[0m of 27\n",
      "2. If India can solve \u001b[1;31mits problem\u001b[0m with respect to water, sanitation and hygiene, you're solving \u001b[1;31mone fifth\u001b[0m of \u001b[1;31mthe world problem\u001b[0m\n",
      "3. \"I don't believe that India is actually headed in \u001b[1;31mthe right direction\u001b[0m and I don't feel very strong here and I feel \u001b[1;31ma great deal\u001b[0m of optimism,\" he says\n",
      "4. \"We cannot afford as \u001b[1;31ma country\u001b[0m to not include \u001b[1;31mour women\u001b[0m\" \u001b[1;31mNalkesh Sarke\u001b[0m: \"We also have combined in the same trench fiber optic cable\n",
      "5. So you can get \u001b[1;31ma broadband connection\u001b[0m with \u001b[1;31mthe final lake\u001b[0m of finishing\"\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "def highlight_key_phrases(notes, key_phrases):\n",
    "    highlighted_notes = notes\n",
    "    for phrase in key_phrases:\n",
    "        highlighted_notes = highlighted_notes.replace(phrase, f'\\033[1;31m{phrase}\\033[0m')\n",
    "    return highlighted_notes\n",
    "\n",
    "highlighted_notes = highlight_key_phrases(''.join(result), key_phrases)\n",
    "\n",
    "# Display the highlighted notes as HTML\n",
    "for i, sentence in enumerate(highlighted_notes.split('.'), 1):\n",
    "    print(f\"{i}. {sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
